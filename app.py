"""Streamlit CSV Insight Assistant â€“ revâ€¯6.0
================================================================
â–ªï¸ **Dynamic, automatic answering** â€”Â if the question mentions a single
  categorical value (city, affiliate, chauffeur, vehicleÂ type, etc.) the
  app now computes the answer *in Python* before falling back to the LLM.
â–ªï¸ Categorical columns = *all* columns with â‰¤Â 150 uniques (string **or**
  numeric) so AffiliateÂ ID now included.
â–ªï¸ Added an â€œâš™ï¸ Filter & summaryâ€ sidebar where the user can slice the data
  on any categorical column and immediately see average / median variance.
â–ªï¸ LLM context trimmed to <â€†4â€¯k tokens by only embedding tables for the
  5Â largest categorical columns + the one matching the userâ€™s question.
â–ªï¸ PDF remains onâ€‘demand.
"""
from __future__ import annotations

import os, re, textwrap, ssl, json
from io import BytesIO
from typing import Optional
from email.message import EmailMessage

import pandas as pd
import streamlit as st
from fpdf import FPDF

OPENAI_MODEL = "gpt-4o-mini"
st.set_page_config("CSV Insight Assistant", page_icon="ğŸ“Š", layout="wide")
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

# â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _to_datetime(s: pd.Series) -> pd.Series: return pd.to_datetime(s, errors="coerce")

def _to_numeric(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s.astype(str).str.replace(r"[^0-9.\-]", "", regex=True), errors="coerce")

def clean_df(df: pd.DataFrame) -> pd.DataFrame:
    for c in df.columns:
        lc = c.lower()
        if any(k in lc for k in ("date", "time")):
            df[c] = _to_datetime(df[c])
        elif any(k in lc for k in ("variance", "amount", "cost", "price")):
            df[c] = _to_numeric(df[c])
    return df

def categorical_columns(df: pd.DataFrame, limit: int = 150):
    cats = []
    for c in df.columns:
        if df[c].nunique(dropna=True) <= limit:
            cats.append(c)
    return cats

def pdf_from_md(title: str, md: str) -> bytes:
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page(); pdf.set_font("Helvetica", size=12)
    plain = re.sub(r"[*`_]", "", md)
    for line in textwrap.wrap(plain, width=90, break_long_words=False):
        pdf.multi_cell(0, 6, line)
    pdf.set_title(title)
    buf = BytesIO(); pdf.output(buf); return buf.getvalue()

# â”€â”€ LLM call â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def ask_llm(system: str, user: str) -> str:
    if not OPENAI_API_KEY:
        return "*(OPENAI_API_KEY missing â€“ cannot call LLM)*"
    import openai; openai.api_key = OPENAI_API_KEY
    resp = openai.chat.completions.create(model=OPENAI_MODEL, temperature=0.2,
        messages=[{"role":"system","content":system},{"role":"user","content":user}])
    return resp.choices[0].message.content.strip()

# â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.title("ğŸ“Š CSV Insight AssistantÂ v6.0")
file = st.file_uploader("Upload CSV", type="csv")
if not file: st.stop()

raw_df = pd.read_csv(file)
df = clean_df(raw_df.copy())
cats = categorical_columns(df)

# â”€ Sidebar filter
st.sidebar.header("âš™ï¸Â Filter & summary")
filter_col = st.sidebar.selectbox("Choose column to filter", ["(none)"] + cats)
subset = df
if filter_col != "(none)":
    options = sorted(df[filter_col].dropna().unique())
    sel = st.sidebar.multiselect("Values", options)
    if sel:
        subset = subset[subset[filter_col].isin(sel)]
    st.sidebar.write(f"Rows after filter: {len(subset):,}")
    if "Rate Variance" in subset.columns:
        st.sidebar.metric("Average variance", f"${subset['Rate Variance'].mean():,.2f}")
        st.sidebar.metric("Median variance", f"${subset['Rate Variance'].median():,.2f}")

st.dataframe(subset.head(500), use_container_width=True)

# â”€ Headline KPIs (always on full df) ------------------------------------
if "Rate Variance" in df.columns:
    rv = df["Rate Variance"].dropna(); over = rv[rv > 0]
    headline = {
        "Total net variance": f"${rv.sum():,.0f}",
        "Avg variance": f"${rv.mean():,.2f}",
        "Median variance": f"${rv.median():,.2f}",
        "Overrun jobs": f"{len(over):,} ({len(over)/len(df):.1%})",
    }
    st.subheader("ğŸ“ŒÂ Headline (entire file)")
    st.table(pd.DataFrame(headline, index=["Value"]))

# â”€ Build summary tables for LLM context ---------------------------------
TABLE_LIMIT = 5            # max tables to include per prompt
ROW_LIMIT = 120            # trim long tables
summary_tables: dict[str,str] = {}
for col in cats:
    tbl = (df[[col, "Rate Variance"]].dropna()
           .groupby(col)["Rate Variance"].mean().round(2)
           .sort_values(ascending=False).head(ROW_LIMIT))
    if not tbl.empty:
        summary_tables[col] = tbl.to_markdown()

# keep largest tables first (by rows) and cap to limit
key_tables = sorted(summary_tables.items(), key=lambda kv: -kv[1].count("\n"))[:TABLE_LIMIT]
context_tables = "\n\n".join(f"=== {k} ===\n{v}" for k, v in key_tables)

# â”€ Chat ---------------------------------------------------------------
if "hist" not in st.session_state: st.session_state.hist = []
for r, m in st.session_state.hist: st.chat_message(r).markdown(m)

q = st.chat_input("Ask about averages, medians, counts â€¦")

# Utility: simple direct answer if question matches pattern "average variance for <value>"

def direct_variance_answer(query: str) -> Optional[str]:
    match = re.search(r"average (?:rate )?variance (?:for|in) (.+?)$", query, re.I)
    if not match or "Rate Variance" not in df.columns:
        return None
    target = match.group(1).strip().strip("? .")
    for col in cats:
        # cast to str for comparison
        mask = df[col].astype(str).str.fullmatch(re.escape(target), case=False, regex=True)
        if mask.any():
            avg = df.loc[mask, "Rate Variance"].mean()
            if pd.notna(avg):
                return f"The average rate variance for **{target}** based on *{col}* is **${avg:,.2f}**."
    return None

if q:
    st.chat_message("user").markdown(q)

    direct = direct_variance_answer(q)
    if direct:
        answer = direct
    else:
        numeric_md = df.describe(include="number").to_markdown()
        context = f"Rows: {len(df):,}\nColumns: {', '.join(df.columns)}\n\nNUMERIC SUMMARY\n{numeric_md}\n\n{context_tables}"
        answer = ask_llm("You are a senior data analyst. Use the tables to answer with exact numbers.",
                         context + f"\n\nQ: {q}\nA:")
    st.chat_message("assistant").markdown(answer)
    st.session_state.hist += [("user", q), ("assistant", answer)]

    with st.expander("ğŸ“„ Export this answer"):
        if st.button("Generate PDF", key=f"pdf_{len(st.session_state.hist)}"):
            st.download_button("â¬‡ï¸ Download PDF", pdf_from_md("CSV Insight Assistant report", answer),
                               "analysis.pdf", "application/pdf", key=f"dl_{len(st.session_state.hist)}")

st.caption("revÂ 6.0 â€“ autoâ€‘computed direct answers plus dynamic filters; falls back to GPTâ€‘4o for complex Qs")
